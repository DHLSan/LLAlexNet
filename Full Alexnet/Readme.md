All layers of the Alexnet architecture, activation functions and all necessary functions, as well as the writing of the entire structure of the architecture within the main function, were carried out in the full_alexnet_code.c file. All Alexnet architecture and all of these functions in it were written with our own effort and were not taken from anywhere. For this reason, tests were made in the main function to understand whether the architecture was working correctly and the results from the layers were observed. In order for the architecture to work properly, the filters in the layers had to be given trained weight parameters. We transferred these trained parameters to the txt file with the code added to the python code. Now we needed to write a separate function to pass the weights in these txt files to the filters in the layers. This function is written as specified in the take_weight_last.c file. The code briefly opens the txt file and fills the numbers in the specified arrays, while doing this, it removes unnecessary signs and symbols in the txt file.

In the Full Alexnet file, there is a completely written version of the Alexnet architecture in C code. In addition, there is a function written to use the weights transferred to the txt file in C code. In the full_alexnet_code.c file, the entire architecture is ready to run, but there is no training in the code. Therefore, the trained weight parameters must be given to the filter, but it can work correctly in this way. As stated before, in order to perform this operation, transferring from python to txt file is performed. However, the Alexnet architecture is divided into 2 parts after the first convolution layer and the operations continue. For this reason, when we try to get the weights, we can only pull half of the weights after the first convolution layer. Despite our great efforts, we could not succeed. Therefore, unfortunately, we could not find the opportunity to test whether the architecture works correctly.
